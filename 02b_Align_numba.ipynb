{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment with Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains numba accelerated implementations of NSDTW, WSDTW, and SSDTW, along with code to conduct runtime experiments on these implementations. It also contains multithreaded and further parallelized implementations of WSDTW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial.distance as dist\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as lb\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import time\n",
    "import gc\n",
    "from numba import jit, njit, float64, uint32, boolean\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Change this cell to suit your file structure #####\n",
    "OUT_ROOT = Path().absolute() # Output root directory (this is where features, paths, etc. will be saved)\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_ROOT = OUT_ROOT / 'features'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTW and Subsequence DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTWDefaultSteps = np.array([[1, 1, 2],\n",
    "                            [1, 2, 1]], dtype = np.uint32)\n",
    "\n",
    "DTWDefaultWeights = np.array([2, 3, 3], dtype = np.float64)\n",
    "\n",
    "\n",
    "subseqDTWDefaultSteps = np.array([[1, 1, 2],\n",
    "                                  [1, 2, 1]], dtype = np.uint32)\n",
    "\n",
    "subseqDTWDefaultWeights = np.array([1, 1, 2], dtype = np.float64)\n",
    "\n",
    "\n",
    "MAX_FLOAT = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def DTW_Cost_To_DandB(C, Steps = DTWDefaultSteps, weights = DTWDefaultWeights, subsequence=False):\n",
    "    '''\n",
    "    Find the accumulated cost matrix and backtrace matrix from a cost matrix using Dynamic time warping\n",
    "    \n",
    "    Arguments:\n",
    "    C -- The Cost matrix\n",
    "    Steps -- The available steps, where the first row is the row steps, the second row is the column steps\n",
    "    weights -- The weights of the steps\n",
    "    subsequence -- True if subsequence DTW should be performed rather than standard DTW\n",
    "             \n",
    "    Returns:\n",
    "    D -- The accumulated cost matrix\n",
    "    B -- The backtrace matrix\n",
    "    '''\n",
    "    '''\n",
    "    Section for verifying input\n",
    "    '''\n",
    "    # Separate steps\n",
    "    rowSteps = Steps[0,:]\n",
    "    colSteps = Steps[1,:]\n",
    "\n",
    "    # Define Relevant Variables\n",
    "    numRows = C.shape[0]\n",
    "    numCols = C.shape[1]\n",
    "    \n",
    "    numDifSteps = len(weights)\n",
    "    maxRowStep = max(rowSteps)\n",
    "    maxColStep = max(colSteps)\n",
    "    \n",
    "    # Set up accumulated cost matrix D and backtrace matrix B\n",
    "    D = np.ones((numRows + maxRowStep, numCols + maxColStep), dtype = np.float64) * MAX_FLOAT\n",
    "    B = np.zeros((numRows, numCols), dtype = np.uint32)\n",
    "    \n",
    "    # Fill up D and B\n",
    "    if subsequence:  # Initialize entire bottom row of D for subsequence\n",
    "        D[maxRowStep, maxColStep:] = C[0,:]\n",
    "    else:\n",
    "        D[maxRowStep, maxColStep] = C[0,0]  # Initialize bottom corner if for standard DTW\n",
    "    for row in range(maxRowStep, numRows + maxRowStep, 1):\n",
    "        for col in range(maxColStep, numCols + maxColStep, 1):\n",
    "            bestCost = D[row, col]\n",
    "            bestCostIndex = 0\n",
    "            # Go through each step, find the best one\n",
    "            for stepIndex in range(numDifSteps):\n",
    "                costForStep = D[row - rowSteps[stepIndex], col - colSteps[stepIndex]] + weights[stepIndex] * C[row - maxRowStep, col - maxColStep]\n",
    "                if costForStep < bestCost:\n",
    "                    bestCost = costForStep\n",
    "                    bestCostIndex = stepIndex\n",
    "            # Save best cost and step\n",
    "            D[row,col] = bestCost\n",
    "            B[row - maxRowStep, col - maxColStep] = bestCostIndex\n",
    "    # Return accumulated cost matrix D and backtrace matrix B\n",
    "    return D[maxRowStep:, maxColStep:], B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def DTW_Backtrace(D, B, Steps=DTWDefaultSteps, subsequence=False, startCol=-1):\n",
    "    '''\n",
    "    Backtrace through an accumulated cost matrix and backtrace matrix to find a path\n",
    "    \n",
    "    Arguments:\n",
    "    D -- The accumulated cost matrix\n",
    "    B -- The backtrace matrix\n",
    "    Steps -- The available steps\n",
    "    subsequence -- True if subsequence DTW should be performed rather than standard DTW\n",
    "    startCol -- The column to begin backtracing from, or -1 if not specified\n",
    "    \n",
    "    Returns:\n",
    "    fwdPath -- A 2d numpy array storing the optimal path. The first row is the path through the rows.\n",
    "            The second row is the path through the columns\n",
    "    '''\n",
    "    '''\n",
    "    Section for verifying input\n",
    "    '''\n",
    "    # Separate steps\n",
    "    rowSteps = Steps[0,:]\n",
    "    colSteps = Steps[1,:]\n",
    "    \n",
    "    # Initialize variables\n",
    "    numRows = D.shape[0]\n",
    "    numCols = D.shape[1]\n",
    "    \n",
    "    curRow = numRows - 1  # Always start at last row\n",
    "    curCol = numCols - 1  # Standard DTW: Start at top-right corner\n",
    "    if startCol >= 0:\n",
    "        curCol = startCol\n",
    "    elif subsequence:  # Subsequence: Choose lowest cost of top row\n",
    "        curCol = np.argmin(D[numRows-1,:])\n",
    "    \n",
    "    endCol = curCol\n",
    "    endCost = D[curRow, curCol]\n",
    "    stepsInPath = 1\n",
    "    stepIndex = 0\n",
    "    done = (subsequence and curRow == 0) or (curRow == 0 and curCol == 0)\n",
    "    path = np.zeros((2, numRows + numCols), dtype=np.uint32) # make as large as could need, then chop at the end\n",
    "    path[0, 0] = curRow\n",
    "    path[1, 0] = curCol\n",
    "    \n",
    "    # Backtrace\n",
    "    while not done:\n",
    "        \n",
    "        if D[curRow, curCol] == MAX_FLOAT:  # No path exists to current location\n",
    "            break\n",
    "        \n",
    "        # you're done if you've made it to the bottom left (non sub-sequence)\n",
    "        # or just the bottom (sub-sequence)\n",
    "        # find the step size\n",
    "        curStepIndex = B[curRow, curCol]\n",
    "        curRowStep = rowSteps[curStepIndex]\n",
    "        curColStep = colSteps[curStepIndex]\n",
    "        # backtrack by 1 step\n",
    "        curRow = curRow - curRowStep\n",
    "        curCol = curCol - curColStep\n",
    "        # add your new location onto the path\n",
    "        path[0, stepsInPath] = curRow\n",
    "        path[1, stepsInPath] = curCol\n",
    "        stepsInPath = stepsInPath + 1\n",
    "        # check to see if you're done\n",
    "        done = (subsequence and curRow == 0) or (curRow == 0 and curCol == 0)\n",
    "        \n",
    "    # reverse the path (a matrix with two rows) and return it\n",
    "    fwdPath = np.fliplr(path[:, 0:stepsInPath])\n",
    "    return fwdPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile this function in object mode to allow for np.load and time profiling\n",
    "@jit(forceobj = True)\n",
    "def DTW(queryFeatureFile, refFeatureFile, Steps = DTWDefaultSteps, weights = DTWDefaultWeights, subsequence = False, \\\n",
    "        outfile = None, profile = False):\n",
    "    '''\n",
    "    Run DTW on query and reference feature matrices\n",
    "    \n",
    "    Arguments:\n",
    "    queryFeatureFile -- The file containing the query feature matrix\n",
    "    refFeatureFile -- The file containing the reference feature matrix\n",
    "    Steps -- The steps matrix. The first row is the steps in along the rows,\n",
    "             the second row is the steps along the columns\n",
    "    weights -- The weights for the steps\n",
    "    subsequence -- True if subsequence DTW should be performed rather than standard DTW\n",
    "    \n",
    "    Returns:\n",
    "    path -- A 2d numpy array storing the optimal path. The first row is the path through the rows.\n",
    "            The second row is the path through the columns\n",
    "    '''\n",
    "    # Extract Feature matrices\n",
    "    F1 = np.load(queryFeatureFile, allow_pickle = True)\n",
    "    F2 = np.load(refFeatureFile, allow_pickle = True)\n",
    "    \n",
    "    # empty file if no valid path possible\n",
    "    if not subsequence and max(F1.shape[1], F2.shape[1]) / min(F1.shape[1], F2.shape[1]) >= 2:\n",
    "        if outfile:\n",
    "            pickle.dump(None, open(outfile, 'wb'))\n",
    "        return None\n",
    "    \n",
    "    # start time logging\n",
    "    times = []\n",
    "    times.append(time.time())\n",
    "    \n",
    "    # Compute Cost Matrix\n",
    "    C = 1 - F1.T @ F2 # cos distance metric\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    # Get D and B\n",
    "    D, B = DTW_Cost_To_DandB(C, Steps = Steps, weights = weights, subsequence=subsequence)\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    # Backtrace and return\n",
    "    wp = DTW_Backtrace(D, B, Steps=Steps, subsequence=subsequence)\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    # logging result if outfile exists\n",
    "    if outfile:\n",
    "        pickle.dump(wp, open(outfile, 'wb'))\n",
    "    \n",
    "    # return extra timing array if profiling timing\n",
    "    if profile:\n",
    "        return wp, np.diff(times)\n",
    "    else:\n",
    "        return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTW_batch(querylist, featdir1, featdir2, outdir, n_cores, steps, weights, subsequence):\n",
    "    \n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # prep inputs for parallelization\n",
    "    inputs = []\n",
    "    with open(querylist, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(' ')\n",
    "            assert len(parts) == 2\n",
    "            featfile1 = (featdir1 / parts[0]).with_suffix('.npy')\n",
    "            featfile2 = (featdir2 / parts[1]).with_suffix('.npy')\n",
    "            queryid = os.path.basename(parts[0]) + '__' + os.path.basename(parts[1])\n",
    "            outfile = (outdir / queryid).with_suffix('.pkl')\n",
    "            if os.path.exists(outfile):\n",
    "                print(f\"Skipping {outfile}\")\n",
    "            else:\n",
    "                inputs.append((featfile1, featfile2, steps, weights, subsequence, outfile))\n",
    "\n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    pool.starmap(DTW, inputs)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = 'cfg_files/query.test.list'\n",
    "featdir1 = FEATURES_ROOT / 'clean'\n",
    "featdir2 = FEATURES_ROOT / 'clean' # in case you want to align clean vs noisy\n",
    "outdir = OUT_ROOT / 'experiments_test/clean/DTW'\n",
    "n_cores = 1\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([2,3,3])\n",
    "subseq = False\n",
    "DTW_batch(query_list, featdir1, featdir2, outdir, n_cores, steps, weights, subseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-ordered Segmental DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile this function in object mode to allow for np.load and time profiling\n",
    "@jit(forceobj = True)\n",
    "def NSDTW(queryFeatureFile, refFeatureFile, segments, Steps = subseqDTWDefaultSteps, weights = subseqDTWDefaultWeights, \\\n",
    "          outfile = None, profile = False):\n",
    "    '''\n",
    "    Runs a non-ordered segmental DTW between query and reference features matrices\n",
    "    \n",
    "    Arguments:\n",
    "    queryFeatureFile -- The file containing the query feature matrix\n",
    "    refFeatureFile -- The file containing the reference feature matrix\n",
    "    segments -- The number of segments to divide F1 into\n",
    "    Steps -- The allowed steps\n",
    "    weights -- The weights for the steps\n",
    "    \n",
    "    Returns:\n",
    "    path -- The optimal non-ordered, segmented alignment path between F1 and F2\n",
    "    '''\n",
    "    # Extract Feature matrices\n",
    "    F1 = np.load(queryFeatureFile, allow_pickle = True)\n",
    "    F2 = np.load(refFeatureFile, allow_pickle = True)\n",
    "\n",
    "    if max(F1.shape[1], F2.shape[1]) / min(F1.shape[1], F2.shape[1]) >= 2: # no valid path possible\n",
    "        if outfile:\n",
    "            pickle.dump(None, open(outfile, 'wb'))\n",
    "        return None\n",
    "    \n",
    "    # start time logging\n",
    "    times = []\n",
    "    times.append(time.time())\n",
    "    \n",
    "    # Compute Cost\n",
    "    C = 1 - F1.T @ F2\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    # Subsequence DTW each segment without backtracing\n",
    "    segLength = int(np.ceil(F1.shape[1] / segments))\n",
    "    Cseg = np.zeros((segments + 1, C.shape[1]), dtype = np.float64)\n",
    "    Dparts = []\n",
    "    Bparts = []\n",
    "    for i in range(segments):\n",
    "        segStart = i * segLength\n",
    "        segEnd = min(segStart + segLength, C.shape[0])\n",
    "        # Ensuring that the segment is contiguous here ensures best performance in later computations\n",
    "        currentSeg = np.ascontiguousarray(C[segStart:segEnd,:])\n",
    "        D_i, B_i = DTW_Cost_To_DandB(currentSeg, Steps = Steps, weights = weights, subsequence = True)\n",
    "        \n",
    "        # Store D_i and B_i for segment\n",
    "        Dparts.append(D_i)\n",
    "        Bparts.append(B_i)\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    # Backtrace through segments with segment level path as guide\n",
    "    # Initialize path: make as large as could need, then chop at the end\n",
    "    path = []\n",
    "    stepsInPath = 0\n",
    "    # Frame level backtrace segment by segment\n",
    "    for i in range(segments):\n",
    "        pathSeg = DTW_Backtrace(Dparts[i], Bparts[i], Steps = Steps, subsequence = True)\n",
    "        # Add offset to row indices so they match with overall path\n",
    "        pathSeg[0,:] = pathSeg[0,:] + (i * segLength)\n",
    "\n",
    "        # Append fragment to full path\n",
    "        path.append(pathSeg.copy())\n",
    "    \n",
    "    wp_merged = np.hstack(path)\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    if outfile:\n",
    "        pickle.dump(wp_merged, open(outfile, 'wb'))\n",
    "\n",
    "    if profile:\n",
    "        return wp_merged, np.diff(times)\n",
    "    else:\n",
    "        return wp_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDTW_batch(querylist, featdir1, featdir2, outdir, n_cores, steps, weights, numSegments, fn):\n",
    "\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # prep inputs for parallelization\n",
    "    inputs = []\n",
    "    with open(querylist, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(' ')\n",
    "            assert len(parts) == 2\n",
    "            featfile1 = (featdir1 / parts[0]).with_suffix('.npy')\n",
    "            featfile2 = (featdir2 / parts[1]).with_suffix('.npy')\n",
    "            queryid = os.path.basename(parts[0]) + '__' + os.path.basename(parts[1])\n",
    "            outfile = (outdir / queryid).with_suffix('.pkl')\n",
    "            if os.path.exists(outfile):\n",
    "                print(f\"Skipping {outfile}\")\n",
    "            else:\n",
    "                inputs.append((featfile1, featfile2, numSegments, steps, weights, outfile))\n",
    "\n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    pool.starmap(fn, inputs)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = 'cfg_files/query.test.list'\n",
    "featdir1 = FEATURES_ROOT / 'clean'\n",
    "featdir2 = FEATURES_ROOT / 'clean' # in case you want to align clean vs noisy\n",
    "\n",
    "n_cores = 1\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([1,1,2])\n",
    "segmentVals = [2, 4, 8, 16, 32] \n",
    "for numSegments in segmentVals:\n",
    "    outdir = OUT_ROOT / f'experiments_test/clean/NSDTW_{numSegments}'\n",
    "    SDTW_batch(query_list, featdir1, featdir2, outdir, n_cores, steps, weights, numSegments, NSDTW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weakly-ordered Segmental DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def getSegmentEndingLocs(wp):\n",
    "    '''\n",
    "    Takes in a segment level path through and returns the columns where each segment ends\n",
    "    \n",
    "    Arguments:\n",
    "    wp -- A segment level path (as a 2d numpy array with 2 rows)\n",
    "    \n",
    "    Returns:\n",
    "    endLocs -- A list where the ith entry is the column where the ith segment ends\n",
    "    '''\n",
    "    prevLoc = wp[:,0] # [r,c]\n",
    "    endLocs = []\n",
    "    for i in range(wp.shape[1]):\n",
    "        curLoc = wp[:,i]\n",
    "        if curLoc[0] != prevLoc[0]: # if row changes\n",
    "            endLocs.append(curLoc[1])\n",
    "        prevLoc = curLoc\n",
    "        \n",
    "    return endLocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile this function in object mode to allow for np.load and time profiling\n",
    "@jit(forceobj = True)\n",
    "def WSDTW(queryFeatureFile, refFeatureFile, segments, Steps = subseqDTWDefaultSteps, weights = subseqDTWDefaultWeights, \\\n",
    "          outfile = None, profile = False):\n",
    "    '''\n",
    "    Runs a weakly-ordered segmental DTW between query and reference features matrices\n",
    "    \n",
    "    Arguments:\n",
    "    queryFeatureFile -- The file containing the query feature matrix\n",
    "    refFeatureFile -- The file containing the reference feature matrix\n",
    "    segments -- The number of segments to divide F1 into\n",
    "    Steps -- The allowed steps\n",
    "    weights -- The weights for the steps\n",
    "    \n",
    "    Returns:\n",
    "    path -- The optimal weakly-ordered, segmented alignment path between F1 and F2\n",
    "    '''\n",
    "    # Extract Feature matrices\n",
    "    F1 = np.load(queryFeatureFile, allow_pickle = True)\n",
    "    F2 = np.load(refFeatureFile, allow_pickle = True)\n",
    "\n",
    "    if max(F1.shape[1], F2.shape[1]) / min(F1.shape[1], F2.shape[1]) >= 2: # no valid path possible\n",
    "        if outfile:\n",
    "            pickle.dump(None, open(outfile, 'wb'))\n",
    "        return None\n",
    "    \n",
    "    # start time logging\n",
    "    times = []\n",
    "    times.append(time.time())\n",
    "    \n",
    "    # Compute Cost\n",
    "    C = 1 - F1.T @ F2\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    # Subsequence DTW each segment without backtracing\n",
    "    segLength = int(np.ceil(F1.shape[1] / segments))\n",
    "    Cseg = np.zeros((segments + 1, C.shape[1]), dtype = np.float64)\n",
    "    Dparts = []\n",
    "    Bparts = []\n",
    "    for i in range(segments):\n",
    "        segStart = i * segLength\n",
    "        segEnd = min(segStart + segLength, C.shape[0])\n",
    "        # Ensuring that the segment is contiguous here ensures best performance in later computations\n",
    "        currentSeg = np.ascontiguousarray(C[segStart:segEnd,:])\n",
    "        D_i, B_i = DTW_Cost_To_DandB(currentSeg, Steps = Steps, weights = weights, subsequence = True)\n",
    "        \n",
    "        # Store D_i and B_i for segment and construct Cseg\n",
    "        Dparts.append(D_i)\n",
    "        Bparts.append(B_i)\n",
    "        \n",
    "        Cseg[i + 1,:] = D_i[-1,:]\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    # run segment-level DTW (Not subsequence)\n",
    "    segmentSteps = np.array([[0, 1],\n",
    "                             [1, C.shape[0]//(2 * segments)]],\n",
    "                            dtype=np.uint32)\n",
    "    segmentWeights = np.array([0, 1])\n",
    "    \n",
    "    Dseg, Bseg = DTW_Cost_To_DandB(Cseg, Steps = segmentSteps, weights = segmentWeights)\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    wpseg = DTW_Backtrace(Dseg, Bseg, Steps=segmentSteps)\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    # Backtrace through segments with segment level path as guide\n",
    "    path = []\n",
    "    # Frame level backtrace segment by segment\n",
    "    segmentEndIdxs = getSegmentEndingLocs(wpseg)\n",
    "        \n",
    "    for i, endidx in enumerate(segmentEndIdxs):\n",
    "        pathSeg = DTW_Backtrace(Dparts[i], Bparts[i], Steps = Steps, subsequence = True, startCol = endidx)\n",
    "        # Add offset to row indices so they match with overall path\n",
    "        pathSeg[0,:] = pathSeg[0,:] + (i * segLength)\n",
    "\n",
    "        # Append fragment to full path\n",
    "        path.append(pathSeg.copy())\n",
    "    \n",
    "    wp_merged = np.hstack(path)\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    if outfile:\n",
    "        pickle.dump(wp_merged, open(outfile, 'wb'))\n",
    "\n",
    "    if profile:\n",
    "        return wp_merged, np.diff(times)\n",
    "    else:\n",
    "        return wp_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = 'cfg_files/query.test.list'\n",
    "featdir1 = FEATURES_ROOT / 'clean'\n",
    "featdir2 = FEATURES_ROOT / 'clean' # in case you want to align clean vs noisy\n",
    "n_cores = 1\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([1,1,2])\n",
    "segmentVals = [2, 4, 8, 16, 32] \n",
    "for numSegments in segmentVals:\n",
    "    outdir = OUT_ROOT / f'experiments_test/clean/WSDTW_{numSegments}'\n",
    "    SDTW_batch(query_list, featdir1, featdir2, outdir, n_cores, steps, weights, numSegments, WSDTW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreded WSDTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WSDTW_multi(F1, F2, K, costMetric = \"cos\", profile = False):\n",
    "    '''\n",
    "    Runs a multi-threaded, parallelized weakly-ordered segmental DTW between two feature matrices\n",
    "    \n",
    "    Arguments:\n",
    "    F1 -- The query feature matrix\n",
    "    F2 -- The reference feature matrix\n",
    "    K -- The number of segments to divide F1 into\n",
    "    costMetric -- The cost metric to use to compute the cost matrix\n",
    "    \n",
    "    Returns:\n",
    "    path -- The optimal weakly-ordered, segmented alignment path between F1 and F2\n",
    "    '''\n",
    "    if max(F1.shape[1], F2.shape[1]) / min(F1.shape[1], F2.shape[1]) >= 2: # no valid path possible\n",
    "        if outfile:\n",
    "            pickle.dump(None, open(outfile, 'wb'))\n",
    "        return None\n",
    "    \n",
    "    # Set up variables\n",
    "    frameSteps = np.array([[1, 1, 2],\n",
    "                           [1, 2, 1]], dtype = np.uint32)\n",
    "\n",
    "    frameWeights = np.array([1, 1, 2], dtype = np.float64)\n",
    "    segLength = int(np.ceil(F1.shape[1] / K))\n",
    "    \n",
    "    times = []\n",
    "    times.append(time.time())\n",
    "    # DTW each segment in parallel\n",
    "    # Set up task list\n",
    "    tasks = [(F1, F2, costMetric, segLength, i) for i in range(K)]\n",
    "    \n",
    "    # Set up pool\n",
    "    with multiprocessing.Pool(processes = K) as p:\n",
    "        times.append(time.time())\n",
    "         # Perform subsequence DTW on each segment in parallel\n",
    "        segmentResults = p.starmap(DTWSegment, tasks)\n",
    "        \n",
    "    times.append(time.time())\n",
    "\n",
    "    # Run segment-level DTW (Not subsequence)\n",
    "    segmentSteps = np.array([[0, 1],\n",
    "                             [1, F1.shape[1]//(2 * K)]],\n",
    "                            dtype=np.uint32)\n",
    "    segmentWeights = np.array([0, 1])\n",
    "    \n",
    "    Cseg = np.zeros((K + 1, F2.shape[1]), dtype = np.float64)\n",
    "    for i, (D_i, _) in enumerate(segmentResults):\n",
    "        Cseg[i+1,:] = D_i[-1,:]\n",
    "\n",
    "    times.append(time.time())\n",
    "\n",
    "    Dseg, Bseg = DTW_Cost_To_DandB(Cseg, Steps = segmentSteps, weights = segmentWeights)\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    wpseg = DTW_Backtrace(Dseg, Bseg, Steps=segmentSteps)\n",
    "    \n",
    "    times.append(time.time())\n",
    "\n",
    "    # Backtrace through segments with segment level path as guide\n",
    "    # Set up task list (use segmentResults)\n",
    "    segmentEndIdxs = getSegmentEndingLocs(wpseg)\n",
    "    backtraceTasks = [(D, B, segmentEndIdxs[i], segLength, i) for i, (D, B) in enumerate(segmentResults)]\n",
    "    \n",
    "    # Perform backtrace in parallel\n",
    "    with multiprocessing.Pool(processes = K) as p:\n",
    "        pathSegments = p.starmap(backtraceSegment, backtraceTasks)\n",
    "    times.append(time.time())\n",
    "    \n",
    "    # Compile path and return\n",
    "    wp_merged = np.concatenate(pathSegments, axis = 1)\n",
    "    if profile:\n",
    "        return wp_merged, np.diff(times)\n",
    "    else:\n",
    "        return wp_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(forceobj = True)\n",
    "def DTWSegment(F1, F2, costMetric, segLength, segNum):\n",
    "    '''\n",
    "    Extracts a single segment of F1 and performs subsequence DTW between it and F2\n",
    "    \n",
    "    Arguments:\n",
    "    F1 -- The query feature matrix\n",
    "    F2 -- The reference feature matrix\n",
    "    costMetric -- The cost metric to use to compute the cost matrix\n",
    "    segLength -- The length of each segment of the query feature matrix\n",
    "    segNum -- The index of the segment to use (0 to K-1, inclusive)\n",
    "    \n",
    "    Returns:\n",
    "    D_i -- The accumulated cost matrix for the relevant segment\n",
    "    B_i -- The backtrace matrix for the relevant segment\n",
    "    '''\n",
    "    # Get segment\n",
    "    seg = extractSegment(F1, segLength, segNum)\n",
    "    \n",
    "    \n",
    "    # Compute costs:\n",
    "    C = dist.cdist(seg.T, F2.T, metric = costMetric)  # scipy's cdist wants dimensions reversed\n",
    "    \n",
    "    # DTW\n",
    "    Steps = np.array([[1, 1, 2],\n",
    "                      [1, 2, 1]], dtype = np.uint32)\n",
    "\n",
    "    weights = np.array([1, 1, 2], dtype = np.float64)\n",
    "    \n",
    "    return DTW_Cost_To_DandB(C, Steps = Steps, weights = weights, subsequence = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def extractSegment(F1, segLength, segNum):\n",
    "    '''\n",
    "    Extracts a single segment of F1\n",
    "    \n",
    "    Arguments:\n",
    "    F1 -- The query feature matrix\n",
    "    segLength -- The length of each segment of the query feature matrix\n",
    "    segNum -- The index of the segment to use (0 to K-1, inclusive)\n",
    "    \n",
    "    Returns:\n",
    "    segment -- A single segment of F1\n",
    "    '''\n",
    "    segStart = segNum * segLength\n",
    "    segEnd = min(segStart + segLength, F1.shape[1])\n",
    "    # Ensuring that the segment is contiguous here ensures best performance in later computations\n",
    "    return np.ascontiguousarray(F1[:,segStart:segEnd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def backtraceSegment(D, B, startCol, segLength, segNum):\n",
    "    '''\n",
    "    Backtrace through a segment and return the path with the row indices offset so they match the overall path\n",
    "    \n",
    "    Arguments:\n",
    "    D -- The cumulative cost matrix for the segment\n",
    "    B -- The backtrace matrix for the segment\n",
    "    startCol -- The column to start backtracing from\n",
    "    segLength -- The length of each segment of the query feature matrix\n",
    "    segNum -- The index of the segment to use (0 to K-1, inclusive)\n",
    "    \n",
    "    Returns:\n",
    "    path -- The path through the segment with the row indices offset so they match the overall path\n",
    "    '''\n",
    "    # Set up variables\n",
    "    Steps = np.array([[1, 1, 2],\n",
    "                      [1, 2, 1]], dtype = np.uint32)\n",
    "    \n",
    "    # Backtrace\n",
    "    path = DTW_Backtrace(D, B, Steps = Steps, subsequence = True, startCol = startCol)\n",
    "    \n",
    "    # Add offset to row indices so they match with overall path\n",
    "    path[0,:] = path[0,:] + (segNum * segLength)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Parallelized WSDTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moreParallelWSDTW(F1, F2, K, M):\n",
    "    '''\n",
    "    Runs a more parallelized version of WSDTW. Each subsequence alignment is parallelized.\n",
    "    \n",
    "    Arguments:\n",
    "    F1 -- The query feature matrix\n",
    "    F2 -- The reference feature matrix\n",
    "    K -- The number of fragments\n",
    "    M -- The number of sub-fragments\n",
    "    \n",
    "    Returns:\n",
    "    wp_merged -- The WSDTW path\n",
    "    '''\n",
    "    Steps = np.array([[1, 1, 2],\n",
    "                      [1, 2, 1]], dtype = np.uint32)\n",
    "\n",
    "    weights = np.array([1, 1, 2], dtype = np.float64)\n",
    "    \n",
    "    if max(F1.shape[1], F2.shape[1]) / min(F1.shape[1], F2.shape[1]) >= 2: # no valid path possible\n",
    "        if outfile:\n",
    "            pickle.dump(None, open(outfile, 'wb'))\n",
    "        return None\n",
    "    \n",
    "    # Compute Cost\n",
    "    C = 1 - F1.T @ F2\n",
    "    \n",
    "    # Subsequence DTW each segment without backtracing\n",
    "    segLength = int(np.ceil(F1.shape[1] / K))\n",
    "    Cseg = np.zeros((K + 1, C.shape[1]), dtype = np.float64)\n",
    "    Dparts = []\n",
    "    Bparts = []\n",
    "    for i in range(K):\n",
    "        segStart = i * segLength\n",
    "        segEnd = min(segStart + segLength, C.shape[0])\n",
    "        # Ensuring that the segment is contiguous here ensures best performance in later computations\n",
    "        currentSeg = np.ascontiguousarray(C[segStart:segEnd,:])\n",
    "        # Further divide each segment into fragments\n",
    "        D_i = np.zeros(currentSeg.shape)\n",
    "        B_i = np.ones(currentSeg.shape)\n",
    "        fragLength = int(np.ceil(currentSeg.shape[1] / M) + 2 * currentSeg.shape[0])\n",
    "        for j in range(M):\n",
    "            fragStart = j * fragLength - j * 2 * currentSeg.shape[0]\n",
    "            fragEnd = min(fragStart + fragLength, currentSeg.shape[1])\n",
    "            currentFrag = currentSeg[:, fragStart:fragEnd]\n",
    "            \n",
    "            D_frag, B_frag = DTW_Cost_To_DandB(currentFrag, Steps = Steps, weights = weights, subsequence = True)\n",
    "            \n",
    "            if fragStart == 0: # Use all of first fragment\n",
    "                D_i[:, 0:fragEnd] = D_frag\n",
    "                B_i[:, 0:fragEnd] = B_frag\n",
    "            else: # Discard overlap for later fragments\n",
    "                D_i[:, fragStart + 2 * currentSeg.shape[0]:fragEnd] = D_frag[:, 2 * currentSeg.shape[0]:]\n",
    "                B_i[:, fragStart + 2 * currentSeg.shape[0]:fragEnd] = B_frag[:, 2 * currentSeg.shape[0]:]        \n",
    "        # Store D_i and B_i for segment and construct Cseg\n",
    "        Dparts.append(D_i)\n",
    "        Bparts.append(B_i)\n",
    "        \n",
    "        Cseg[i + 1,:] = D_i[-1,:]\n",
    "\n",
    "    # run segment-level DTW (Not subsequence)\n",
    "    segmentSteps = np.array([[0, 1],\n",
    "                             [1, C.shape[0]//(2 * K)]],\n",
    "                            dtype=np.uint32)\n",
    "    segmentWeights = np.array([0, 1])\n",
    "    \n",
    "    Dseg, Bseg = DTW_Cost_To_DandB(Cseg, Steps = segmentSteps, weights = segmentWeights)\n",
    "    wpseg = DTW_Backtrace(Dseg, Bseg, Steps=segmentSteps)\n",
    "    \n",
    "    # Backtrace through segments with segment level path as guide\n",
    "    path = []\n",
    "    # Frame level backtrace segment by segment\n",
    "    segmentEndIdxs = getSegmentEndingLocs(wpseg)\n",
    "    for i, endidx in enumerate(segmentEndIdxs):\n",
    "        pathSeg = DTW_Backtrace(Dparts[i], Bparts[i], Steps = Steps, subsequence = True, startCol = endidx)\n",
    "        # Add offset to row indices so they match with overall path\n",
    "        pathSeg[0,:] = pathSeg[0,:] + (i * segLength)\n",
    "\n",
    "        # Append fragment to full path\n",
    "        path.append(pathSeg.copy())\n",
    "    \n",
    "    wp_merged = np.hstack(path)\n",
    "\n",
    "    return wp_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strongly-ordered Segmental DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def SSDTW_Segment_Level_DTW(Cseg, Tseg):\n",
    "    '''\n",
    "    Performs the segment level DTW for strongly-ordered segmental DTW\n",
    "    Steps not required because they are variable based on Tseg\n",
    "    \n",
    "    Arguments:\n",
    "    Cseg -- The segment level cost matrix\n",
    "    Tseg -- A matrix where the i,jth entry is the column of the optimal path through segment i ending at column j.\n",
    "            This is used to determine the possible segment level steps that ensure strong ordering\n",
    "            \n",
    "    Returns:\n",
    "    Dseg -- The segment level accumulated cost matrix\n",
    "    Bseg -- The segment level backtrace matrix. Since steps are variable, the i, jth entry of the backtrace matrix\n",
    "            stores either -1 for a (1, 0) \"skip\" step or the colStep value of a (1, colStep) step ending at i,j\n",
    "    '''\n",
    "\n",
    "    # Define Relevant Variables\n",
    "    numRows = Cseg.shape[0]\n",
    "    numCols = Cseg.shape[1]\n",
    "    \n",
    "    # Set up accumulated cost matrix D and backtrace matrix B\n",
    "    Dseg = np.ones((numRows + 1, numCols), dtype = np.float64) * MAX_FLOAT\n",
    "    Dseg[0,:] = 0\n",
    "    \n",
    "    # (0,1) transition by default\n",
    "    Bseg = np.zeros((numRows+1, numCols), dtype = np.int32) - 1\n",
    "    \n",
    "    # Fill up D and B\n",
    "    for row in range(1, numRows+1):\n",
    "        for col in range(numCols):\n",
    "            # (0,1) transition is skip with weight 0\n",
    "            if col==0:\n",
    "                skipCost = MAX_FLOAT\n",
    "            else:\n",
    "                skipCost = Dseg[row, col-1]\n",
    "            Dseg[row, col] = skipCost\n",
    "            \n",
    "            traverseStartCol = Tseg[row-1,col]\n",
    "            if traverseStartCol >= 0: # is it possible to traverse previous segment and end up here?\n",
    "                # Traverse segment with weight 1\n",
    "                traverseSegCost = Dseg[row-1, traverseStartCol] + Cseg[row-1, col]\n",
    "                # If traversing here is best option, store the column where the path starts\n",
    "                if traverseSegCost < skipCost:\n",
    "                    Dseg[row, col] = traverseSegCost\n",
    "                    # TraverseStartCol represents where to start backtracing in the next row\n",
    "                    Bseg[row, col] = traverseStartCol\n",
    "    \n",
    "    return Dseg, Bseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def SSDTW_Segment_Level_Backtrace(Dseg, Bseg):\n",
    "    '''\n",
    "    Backtraces through segments enforcing a strongly-ordered path\n",
    "    \n",
    "    Arguments:\n",
    "    Dseg -- The segmental accumulated cost matrix\n",
    "    Bseg -- The segmental backtrace matrix. Stores -1 for (0,1) transitions and colStep for (1, colStep) transitions\n",
    "    \n",
    "    Returns:\n",
    "    path -- A vector where the ith element is the column where the ith segment should end\n",
    "    '''\n",
    "    # Initialize variables\n",
    "    numRows = Dseg.shape[0]\n",
    "    numCols = Dseg.shape[1]\n",
    "    curRow = numRows - 1\n",
    "    curCol = numCols - 1\n",
    "    # Path will have one entry for every row except for the bottom one\n",
    "    path = np.zeros(numRows-1, dtype = np.uint32)\n",
    "    stepsInPath = 0\n",
    "        \n",
    "    # Backtrace until reaching bottom row\n",
    "    while curRow > 0:\n",
    "        \n",
    "        if Dseg[curRow, curCol] == MAX_FLOAT:\n",
    "            print('A path is not possible')\n",
    "            break\n",
    "        \n",
    "        # (1,0) \"skip\" transitions (-1 in Bseg) do not get added to path\n",
    "        if Bseg[curRow, curCol] < 0:\n",
    "            curCol = curCol - 1\n",
    "        # For segment traversals, store segment end location in the path.\n",
    "        else:\n",
    "            path[stepsInPath] = curCol\n",
    "            # Continue backtracing where the segment tranversal began\n",
    "            curCol = Bseg[curRow, curCol]\n",
    "            curRow = curRow - 1\n",
    "            stepsInPath = stepsInPath + 1\n",
    "    # Remember to flip the backtraced path\n",
    "    return path[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def calcTseg(D_i, B_i, Steps = subseqDTWDefaultSteps):\n",
    "    '''\n",
    "    Calculate a row of Tseg for SSDTW from the the accumulated cost and backtrace matrix for that segment\n",
    "    \n",
    "    Arguments:\n",
    "    D_i -- The accumulated cost matrix for the ith segment\n",
    "    B_i -- The backtrace matrix for the ith segment\n",
    "    Steps -- The available steps\n",
    "    \n",
    "    Returns:\n",
    "    Tseg_i -- The ith row of Tseg\n",
    "    '''\n",
    "    # Initializing variables\n",
    "    numRows = D_i.shape[0]\n",
    "    numCols = D_i.shape[1]\n",
    "    rowSteps = Steps[0,:]\n",
    "    colSteps = Steps[1,:]\n",
    "    # Default to -1, meaning no path ending at that location is possible\n",
    "    Tseg_i = np.zeros(numCols, dtype = np.uint32) - 1\n",
    "    \n",
    "    # Fill in Tseg_i by backtracing from each column\n",
    "    # backtrace from every location\n",
    "    for endCol in range(numCols):\n",
    "        curCol = endCol\n",
    "        curRow = numRows - 1\n",
    "        while curRow > 0:\n",
    "            if D_i[curRow, curCol] == MAX_FLOAT: # no valid path\n",
    "                Tseg_i[curCol] = -1\n",
    "                break\n",
    "\n",
    "            curStepIndex = B_i[curRow, curCol]\n",
    "            curRow = curRow - rowSteps[curStepIndex]\n",
    "            curCol = curCol - colSteps[curStepIndex]\n",
    "            if curRow == 0:\n",
    "                Tseg_i[endCol] = curCol\n",
    "    \n",
    "    return Tseg_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile this function in object mode to allow for np.load and time profiling\n",
    "@jit(forceobj = True)\n",
    "def SSDTW(queryFeatureFile, refFeatureFile, segments, Steps = subseqDTWDefaultSteps, weights = subseqDTWDefaultWeights, \\\n",
    "          outfile=None, profile=False):\n",
    "    '''\n",
    "    Aligns query and reference with strictly-ordered segmental DTW\n",
    "    \n",
    "    Arguments:\n",
    "    queryFeatureFile -- The file containing the query feature matrix\n",
    "    refFeatureFile -- The file containing the reference feature matrix\n",
    "    segments -- The number of segments\n",
    "    Steps -- The allowable steps\n",
    "    weights -- The weights of the steps\n",
    "    \n",
    "    Returns:\n",
    "    path -- The optimal strictly ordered segmental path\n",
    "    '''\n",
    "    # Extract Feature matrices\n",
    "    F1 = np.load(queryFeatureFile, allow_pickle = True)\n",
    "    F2 = np.load(refFeatureFile, allow_pickle = True)\n",
    "    \n",
    "\n",
    "    swap = (F1.shape[1] > F2.shape[1])\n",
    "    if swap:\n",
    "        F1, F2 = F2, F1 # make the shorter sequence the query\n",
    "        \n",
    "    \n",
    "    if F2.shape[1] / F1.shape[1] >= 2: # no valid path possible\n",
    "        if max(F1.shape[1], F2.shape[1]) / min(F1.shape[1], F2.shape[1]) >= 2: # no valid path possible\n",
    "            if outfile:\n",
    "                pickle.dump(None, open(outfile, 'wb'))\n",
    "            return None\n",
    "    \n",
    "    # start time logging\n",
    "    times = []\n",
    "    times.append(time.time())\n",
    "    \n",
    "    # Compute Cost\n",
    "    C = 1 - F1.T @ F2\n",
    "    \n",
    "    times.append(time.time())\n",
    "        \n",
    "    # Subsequence DTW each segment without backtracing\n",
    "    segLength = int(np.ceil(F1.shape[1] / segments))\n",
    "    Cseg = np.zeros((segments, C.shape[1]), dtype = np.float64)\n",
    "    Tseg = np.zeros((segments, F2.shape[1]), dtype=np.int32)\n",
    "    Dparts = []\n",
    "    Bparts = []\n",
    "    \n",
    "    for i in range(segments):\n",
    "        \n",
    "        segStart = i * segLength\n",
    "        segEnd = min(segStart + segLength, C.shape[0])\n",
    "        # Ensuring that the segment is contiguous here ensures best performance in later computations\n",
    "        currentSeg = np.ascontiguousarray(C[segStart:segEnd,:])\n",
    "        D_i, B_i = DTW_Cost_To_DandB(currentSeg, Steps = Steps, weights = weights, subsequence = True)\n",
    "        \n",
    "        # Store D_i and B_i for segment and construct Cseg\n",
    "        Dparts.append(D_i)\n",
    "        Bparts.append(B_i)\n",
    "        \n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    for i in range(segments):\n",
    "        D_i = Dparts[i]\n",
    "        B_i = Bparts[i]\n",
    "        Cseg[i,:] = D_i[-1,:]\n",
    "        Tseg[i,:] = calcTseg(D_i, B_i, Steps=Steps)\n",
    "    \n",
    "    times.append(time.time())\n",
    "    # run segment-level DTW (Not subsequence)\n",
    "    Dseg, Bseg = SSDTW_Segment_Level_DTW(Cseg, Tseg)\n",
    "    \n",
    "    times.append(time.time())\n",
    "        \n",
    "    segmentEndIdxs = SSDTW_Segment_Level_Backtrace(Dseg, Bseg)\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    # Frame level backtrace segment by segment\n",
    "    path = []\n",
    "    for i, endidx in enumerate(segmentEndIdxs):\n",
    "        pathSeg = DTW_Backtrace(Dparts[i], Bparts[i], Steps = Steps, subsequence = True, startCol = endidx)\n",
    "        \n",
    "        # Add offset to row indices so they match with overall path\n",
    "        pathSeg[0,:] = pathSeg[0,:] + (i * segLength)\n",
    "\n",
    "        # Append fragment to full path\n",
    "        path.append(pathSeg.copy())\n",
    "    \n",
    "    wp_merged = np.hstack(path)\n",
    "    \n",
    "    times.append(time.time())\n",
    "    \n",
    "    # Again, this swap is based on the old implementation\n",
    "    if swap:\n",
    "        wp_merged = np.flipud(wp_merged) # undo swap\n",
    "        \n",
    "    if outfile:\n",
    "        pickle.dump(wp_merged, open(outfile, 'wb'))\n",
    "    \n",
    "    if profile:\n",
    "        return wp_merged, np.diff(times)\n",
    "    else:\n",
    "        return wp_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = 'cfg_files/query.test.list'\n",
    "featdir1 = FEATURES_ROOT / 'clean'\n",
    "featdir2 = FEATURES_ROOT / 'clean' # in case you want to align clean vs noisy\n",
    "n_cores = 1\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([1,1,2])\n",
    "segmentVals = [2, 4, 8, 16, 32]\n",
    "for numSegments in segmentVals:\n",
    "    outdir = OUT_ROOT / f'experiments_test/clean/SSDTW_{numSegments}'\n",
    "    SDTW_batch(query_list, featdir1, featdir2, outdir, n_cores, steps, weights, numSegments, SSDTW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newSegDTW",
   "language": "python",
   "name": "newsegdtw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
